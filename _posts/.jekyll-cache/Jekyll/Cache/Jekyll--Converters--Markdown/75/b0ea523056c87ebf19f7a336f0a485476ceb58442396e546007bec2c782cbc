I"¦O<ul id="markdown-toc">
  <li><a href="#nlp-çš„æ–‡æœ¬ç›¸ä¼¼åº¦çŸ­è¯­å•è¯å¥å­" id="markdown-toc-nlp-çš„æ–‡æœ¬ç›¸ä¼¼åº¦çŸ­è¯­å•è¯å¥å­">NLP çš„æ–‡æœ¬ç›¸ä¼¼åº¦(çŸ­è¯­ã€å•è¯ã€å¥å­)</a></li>
  <li><a href="#å‰è¨€" id="markdown-toc-å‰è¨€">å‰è¨€</a></li>
  <li><a href="#æ–‡ç« ç»“æ„" id="markdown-toc-æ–‡ç« ç»“æ„">æ–‡ç« ç»“æ„</a></li>
  <li><a href="#ç¬¬ä¸€éƒ¨åˆ†" id="markdown-toc-ç¬¬ä¸€éƒ¨åˆ†">ç¬¬ä¸€éƒ¨åˆ†</a>    <ul>
      <li><a href="#å’Œbertçš„ç›¸ä¼¼åº¦è®¡ç®—çš„å¯¹æ¯”-bertcosineçš„åº¦é‡" id="markdown-toc-å’Œbertçš„ç›¸ä¼¼åº¦è®¡ç®—çš„å¯¹æ¯”-bertcosineçš„åº¦é‡">å’ŒBERTçš„ç›¸ä¼¼åº¦è®¡ç®—çš„å¯¹æ¯”ï¼Œ BERT+COSINEçš„åº¦é‡</a></li>
      <li><a href="#2--å¼€å¤´çš„å°æ•°éƒ¨åˆ†-æ˜¯èšç±»çš„ç›¸ä¼¼åº¦é˜ˆå€¼" id="markdown-toc-2--å¼€å¤´çš„å°æ•°éƒ¨åˆ†-æ˜¯èšç±»çš„ç›¸ä¼¼åº¦é˜ˆå€¼">2.  å¼€å¤´çš„å°æ•°éƒ¨åˆ† ã€€æ˜¯èšç±»çš„ç›¸ä¼¼åº¦é˜ˆå€¼</a></li>
    </ul>
  </li>
  <li><a href="#æ€»ç»“" id="markdown-toc-æ€»ç»“">æ€»ç»“ï¼š</a>    <ul>
      <li><a href="#1-æ˜æ˜¾çœ‹å‡ºè‡ªç”±è¡Œåº¦å‡å’Œåº¦å‡è‡ªç”±è¡Œçš„ç›¸ä¼¼åº¦æ˜¯é«˜äºå‰ä¸¤ä¸ªçš„è¯æ˜bertä½“ç³»å¯ä»¥å¾ˆå¥½èµ·åˆ°ç¼–è¾‘è·ç¦»çš„ä½œç”¨" id="markdown-toc-1-æ˜æ˜¾çœ‹å‡ºè‡ªç”±è¡Œåº¦å‡å’Œåº¦å‡è‡ªç”±è¡Œçš„ç›¸ä¼¼åº¦æ˜¯é«˜äºå‰ä¸¤ä¸ªçš„è¯æ˜bertä½“ç³»å¯ä»¥å¾ˆå¥½èµ·åˆ°ç¼–è¾‘è·ç¦»çš„ä½œç”¨">1. æ˜æ˜¾çœ‹å‡ºè‡ªç”±è¡Œåº¦å‡å’Œåº¦å‡è‡ªç”±è¡Œçš„ç›¸ä¼¼åº¦ï¼Œæ˜¯é«˜äºå‰ä¸¤ä¸ªçš„ï¼Œè¯æ˜BERTä½“ç³»å¯ä»¥å¾ˆå¥½èµ·åˆ°ç¼–è¾‘è·ç¦»çš„ä½œç”¨ã€‚</a></li>
      <li><a href="#2-æ ¹æ®èšç±»çš„å…³é”®æ˜¯ç”±ç›¸ä¼¼åº¦çš„åº¦é‡å†³å®šä¸ºäº†è·å–æ›´å¥½çš„è¯å‘é‡ç©ºé—´åº”è¯¥æ›´å¤šåœ°ä½¿ç”¨metrciä»»åŠ¡çš„finetuneæ•´ä¸ªbertæ¨¡å‹" id="markdown-toc-2-æ ¹æ®èšç±»çš„å…³é”®æ˜¯ç”±ç›¸ä¼¼åº¦çš„åº¦é‡å†³å®šä¸ºäº†è·å–æ›´å¥½çš„è¯å‘é‡ç©ºé—´åº”è¯¥æ›´å¤šåœ°ä½¿ç”¨metrciä»»åŠ¡çš„finetuneæ•´ä¸ªbertæ¨¡å‹">2. æ ¹æ®èšç±»çš„å…³é”®æ˜¯ç”±ç›¸ä¼¼åº¦çš„åº¦é‡å†³å®šï¼Œä¸ºäº†è·å–æ›´å¥½çš„è¯å‘é‡ç©ºé—´ï¼Œåº”è¯¥æ›´å¤šåœ°ä½¿ç”¨metrciä»»åŠ¡çš„finetuneæ•´ä¸ªbertæ¨¡å‹.</a></li>
      <li><a href="#3-æ­£å¦‚bm25bertæ¨¡å‹åº”ç”¨äºæ–‡æœ¬æœç´¢bertå¯ä»¥ä½œä¸ºæ™®é€‚åœ°è¯åµŒå…¥ç©ºé—´åˆå§‹å‚æ•°æ•´ä½“çš„ä»»åŠ¡åº”è¯¥é¢å‘å…·ä½“ä»»åŠ¡åœºæ™¯è¿›è¡Œè¿‡æ‹Ÿåˆçš„finetuneè®­ç»ƒæ‰“é€ ç‰¹æ®Šé¢†åŸŸçš„è¯å‘é‡è¡¨ç¤ºå¾ˆé•¿æ—¶é—´å†…å°†ä¼šæ˜¯nlpå„å¤§nluä»»åŠ¡çš„å‘å±•å’Œæ¢ç´¢æ–¹å‘æŒç»­éœ¸æ¦œå„å¤§ä»»åŠ¡çš„sota" id="markdown-toc-3-æ­£å¦‚bm25bertæ¨¡å‹åº”ç”¨äºæ–‡æœ¬æœç´¢bertå¯ä»¥ä½œä¸ºæ™®é€‚åœ°è¯åµŒå…¥ç©ºé—´åˆå§‹å‚æ•°æ•´ä½“çš„ä»»åŠ¡åº”è¯¥é¢å‘å…·ä½“ä»»åŠ¡åœºæ™¯è¿›è¡Œè¿‡æ‹Ÿåˆçš„finetuneè®­ç»ƒæ‰“é€ ç‰¹æ®Šé¢†åŸŸçš„è¯å‘é‡è¡¨ç¤ºå¾ˆé•¿æ—¶é—´å†…å°†ä¼šæ˜¯nlpå„å¤§nluä»»åŠ¡çš„å‘å±•å’Œæ¢ç´¢æ–¹å‘æŒç»­éœ¸æ¦œå„å¤§ä»»åŠ¡çš„sota">3. æ­£å¦‚BM25+Bertæ¨¡å‹ï¼Œåº”ç”¨äºæ–‡æœ¬æœç´¢ï¼ŒBertå¯ä»¥ä½œä¸ºæ™®é€‚åœ°è¯åµŒå…¥ç©ºé—´åˆå§‹å‚æ•°ã€‚æ•´ä½“çš„ä»»åŠ¡åº”è¯¥ï¼Œé¢å‘å…·ä½“ä»»åŠ¡åœºæ™¯è¿›è¡Œè¿‡æ‹Ÿåˆçš„finetuneè®­ç»ƒï¼Œæ‰“é€ ç‰¹æ®Šé¢†åŸŸçš„è¯å‘é‡è¡¨ç¤ºï½ï½ï¼Œå¾ˆé•¿æ—¶é—´å†…å°†ä¼šæ˜¯NLPå„å¤§NLUä»»åŠ¡çš„å‘å±•å’Œæ¢ç´¢æ–¹å‘ï¼ŒæŒç»­éœ¸æ¦œå„å¤§ä»»åŠ¡çš„SOTA.</a></li>
    </ul>
  </li>
  <li><a href="#bertå‡ºç°å‰2016å¹´çš„kaggleæ–‡æœ¬ç›¸ä¼¼åº¦å¤§èµ›çš„å† å†›æ–¹æ¡ˆ" id="markdown-toc-bertå‡ºç°å‰2016å¹´çš„kaggleæ–‡æœ¬ç›¸ä¼¼åº¦å¤§èµ›çš„å† å†›æ–¹æ¡ˆ">Bertå‡ºç°å‰2016å¹´çš„kaggleæ–‡æœ¬ç›¸ä¼¼åº¦å¤§èµ›çš„å† å†›æ–¹æ¡ˆï½</a>    <ul>
      <li><a href="#è¿™ä¸ªæ–¹æ¡ˆé›†æˆäº†å¤šç§ä¼ ç»Ÿç‰¹å¾æå–æ–¹æ¡ˆä½¿ç”¨äº†bertä¹‹å‰æœ€å¥½çš„è¯å‘é‡è¡¨å¾æ–¹æ¡ˆglove-ç»“åˆçŸ©é˜µåˆ†è§£å’Œword2vec-çš„è¯å‘é‡ç”Ÿæˆæ–¹æ¡ˆ" id="markdown-toc-è¿™ä¸ªæ–¹æ¡ˆé›†æˆäº†å¤šç§ä¼ ç»Ÿç‰¹å¾æå–æ–¹æ¡ˆä½¿ç”¨äº†bertä¹‹å‰æœ€å¥½çš„è¯å‘é‡è¡¨å¾æ–¹æ¡ˆglove-ç»“åˆçŸ©é˜µåˆ†è§£å’Œword2vec-çš„è¯å‘é‡ç”Ÿæˆæ–¹æ¡ˆ">è¿™ä¸ªæ–¹æ¡ˆé›†æˆäº†å¤šç§ä¼ ç»Ÿç‰¹å¾æå–æ–¹æ¡ˆï¼Œä½¿ç”¨äº†Bertä¹‹å‰æœ€å¥½çš„è¯å‘é‡è¡¨å¾æ–¹æ¡ˆGlove, ç»“åˆçŸ©é˜µåˆ†è§£å’Œword2vec çš„è¯å‘é‡ç”Ÿæˆæ–¹æ¡ˆã€‚</a></li>
      <li><a href="#tokenizer--stanford-corenlp-to-tokenizer" id="markdown-toc-tokenizer--stanford-corenlp-to-tokenizer">Tokenizer : stanford corenlp to tokenizer</a></li>
      <li><a href="#postagger-and-ner---postagger-and--ner-to-preprocessing-text-input-for-some-deep-learning-models" id="markdown-toc-postagger-and-ner---postagger-and--ner-to-preprocessing-text-input-for-some-deep-learning-models">Postagger and Ner :  postagger and  ner to preprocessing text input for some deep learning models</a></li>
    </ul>
  </li>
  <li><a href="#structural-features-ie-from-graph" id="markdown-toc-structural-features-ie-from-graph">Structural features (i.e from graph)</a>    <ul>
      <li><a href="#ä½¿ç”¨å›¾æå–ç‰¹å¾" id="markdown-toc-ä½¿ç”¨å›¾æå–ç‰¹å¾">ä½¿ç”¨å›¾æå–ç‰¹å¾</a></li>
      <li><a href="#å¦‚ä½•å»ºå›¾å’Œä½¿ç”¨å›¾æå–ç‰¹å¾" id="markdown-toc-å¦‚ä½•å»ºå›¾å’Œä½¿ç”¨å›¾æå–ç‰¹å¾">å¦‚ä½•å»ºå›¾å’Œä½¿ç”¨å›¾æå–ç‰¹å¾ï½</a></li>
    </ul>
  </li>
  <li><a href="#models" id="markdown-toc-models">Models</a></li>
  <li><a href="#bertæ–‡æœ¬ç›¸ä¼¼æ€§çš„å…¸å‹æ¡ˆä¾‹-åˆ©ç”¨é¢„è®­ç»ƒçš„ä¸­æ–‡æ¨¡å‹å®ç°åŸºäºbertçš„è¯­ä¹‰åŒ¹é…æ¨¡å‹-æ•°æ®é›†ä¸ºlcqmcæ•°æ®é›†" id="markdown-toc-bertæ–‡æœ¬ç›¸ä¼¼æ€§çš„å…¸å‹æ¡ˆä¾‹-åˆ©ç”¨é¢„è®­ç»ƒçš„ä¸­æ–‡æ¨¡å‹å®ç°åŸºäºbertçš„è¯­ä¹‰åŒ¹é…æ¨¡å‹-æ•°æ®é›†ä¸ºlcqmcæ•°æ®é›†">Bertæ–‡æœ¬ç›¸ä¼¼æ€§çš„å…¸å‹æ¡ˆä¾‹ åˆ©ç”¨é¢„è®­ç»ƒçš„ä¸­æ–‡æ¨¡å‹å®ç°åŸºäºBertçš„è¯­ä¹‰åŒ¹é…æ¨¡å‹ æ•°æ®é›†ä¸ºLCQMCæ•°æ®é›†</a></li>
  <li><a href="#lstmå¥å­ç›¸ä¼¼åº¦åˆ†æ" id="markdown-toc-lstmå¥å­ç›¸ä¼¼åº¦åˆ†æ">LSTMå¥å­ç›¸ä¼¼åº¦åˆ†æ</a></li>
  <li><a href="#query-çš„è§„åˆ™åŒ¹é…" id="markdown-toc-query-çš„è§„åˆ™åŒ¹é…">query çš„è§„åˆ™åŒ¹é…</a>    <ul>
      <li><a href="#é€Ÿåº¦å¿«-å¯æ§æ˜“äºå®ç°é«˜æ•ˆ" id="markdown-toc-é€Ÿåº¦å¿«-å¯æ§æ˜“äºå®ç°é«˜æ•ˆ">é€Ÿåº¦å¿«ï¼Œ å¯æ§ï¼Œæ˜“äºå®ç°ï¼Œé«˜æ•ˆã€‚</a></li>
    </ul>
  </li>
  <li><a href="#æ·±åº¦å­¦ä¹ è¯­ä¹‰åŒ¹é…" id="markdown-toc-æ·±åº¦å­¦ä¹ è¯­ä¹‰åŒ¹é…">æ·±åº¦å­¦ä¹ è¯­ä¹‰åŒ¹é…</a></li>
</ul>

<h2 id="nlp-çš„æ–‡æœ¬ç›¸ä¼¼åº¦çŸ­è¯­å•è¯å¥å­">NLP çš„æ–‡æœ¬ç›¸ä¼¼åº¦(çŸ­è¯­ã€å•è¯ã€å¥å­)</h2>
<h2 id="å‰è¨€">å‰è¨€</h2>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ï¼Œä¼šç»å¸¸æ¶‰åŠå‡ ç§è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬ç›¸ä¼¼åº¦çš„é—®é¢˜ã€‚æå‡ä¿¡æ¯æ£€ç´¢ç³»ç»Ÿçš„å¬å›ç‡ï¼Œé—®ç­”ç³»ç»Ÿä¸­çš„ï¼Œéœ€è¦è®¡ç®—çš„queryå’Œå€™é€‰é›†çš„ç›¸ä¼¼åº¦;  ## æ–‡æœ¬ç›¸ä¼¼åº¦æ–¹æ³• * åŸºäºç»Ÿè®¡çš„æ–¹æ³•     ä¸»è¦æ˜¯æ— ç›‘ç£å­¦ä¹ ï¼Œå¥å­ã€æ®µè½, è¾ƒå¤§ç²’åº¦çš„æ–‡æœ¬ã€‚ * åŸºäºè¯­ä¹‰çš„æ–¹æ³•     å¤§éƒ¨åˆ†æ˜¯åŸºäºæ·±åº¦å­¦ä¹ çš„æœ‰ç›‘ç£å­¦ä¹ ï¼Œä¸€èˆ¬è¯è¯­æˆ–å¥å­, è¾ƒå°ç²’åº¦çš„æ–‡æœ¬ã€‚
</code></pre></div></div>

<h2 id="æ–‡ç« ç»“æ„">æ–‡ç« ç»“æ„</h2>
<ol>
  <li>å¸¸è§çš„å‡ ç§ç›¸ä¼¼æ€§æ¯”è¾ƒæ–¹æ³•</li>
</ol>

<ul>
  <li>
    <p>åŸºäºè¯å‘é‡</p>
  </li>
  <li>
    <p>åŸºäºå­—ç¬¦</p>
  </li>
  <li>
    <p>åŸºäºæ¦‚ç‡ç»Ÿè®¡</p>
  </li>
  <li>
    <p>åŸºäºè¯åµŒå…¥æ¨¡å‹</p>
  </li>
</ul>

<ol>
  <li>State of the art çš„å‡ ç§ä»£è¡¨æ€§æ–¹æ³•</li>
</ol>

<h2 id="ç¬¬ä¸€éƒ¨åˆ†">ç¬¬ä¸€éƒ¨åˆ†</h2>
<ol>
  <li>
    <p>è±æ–‡æ–¯å¦è·ç¦»(ç¼–è¾‘è·ç¦»)
ä¸€ä¸ªå­—ç¬¦ä¸²æ”¹æˆå¦ä¸€ä¸ªå­—ç¬¦ä¸²çš„æœ€å°‘ç¼–è¾‘æ“ä½œï¼Œâ€œåº¦å‡è‡ªç”±è¡Œâ€å’Œâ€œè‡ªç”±è¡Œåº¦å‡â€ï¼Œä¸­æ–‡æ„æ€å®Œå…¨ä¸€æ ·ï¼Œä½†æ˜¯ç¼–è¾‘è·ç¦»æ˜¯5ï¼Œ è¡¨ç¤ºç›¸ä¼¼åº¦å¾ˆä½ã€‚</p>
  </li>
  <li>
    <p>æ¬§å¼å’Œä½™å¼¦è·ç¦»
åŸºäºå‘é‡ç©ºé—´çš„è·ç¦»åº¦é‡æ–¹æ³•</p>
  </li>
</ol>

<h3 id="å’Œbertçš„ç›¸ä¼¼åº¦è®¡ç®—çš„å¯¹æ¯”-bertcosineçš„åº¦é‡">å’ŒBERTçš„ç›¸ä¼¼åº¦è®¡ç®—çš„å¯¹æ¯”ï¼Œ BERT+COSINEçš„åº¦é‡</h3>
<ol>
  <li>åˆ©ç”¨Bertè®¡ç®—å•è¯æˆ–è€…çŸ­è¯­ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚</li>
</ol>

<p>ä¸­å›½è¶³åå’Œä¸­å›½è¶³çƒçš„å‘é‡ç›¸ä¼¼åº¦: 0.94828343
ä¸­å›½è¶³åå’Œä¸­å›½ç¯®åçš„å‘é‡ç›¸ä¼¼åº¦: 0.9531492
è‡ªç”±è¡Œåº¦å‡å’Œåº¦å‡è‡ªç”±è¡Œç›¸ä¼¼åº¦: 0.97110826</p>

<ol>
  <li>åˆ©ç”¨Bertèšç±»çš„ç»“æœ</li>
</ol>

<h3 id="2--å¼€å¤´çš„å°æ•°éƒ¨åˆ†-æ˜¯èšç±»çš„ç›¸ä¼¼åº¦é˜ˆå€¼">2.  å¼€å¤´çš„å°æ•°éƒ¨åˆ† ã€€æ˜¯èšç±»çš„ç›¸ä¼¼åº¦é˜ˆå€¼</h3>
<p>0.92
[â€˜æœˆå…‰â€™, â€˜æœˆè‰²â€™, â€˜å¤•é˜³â€™, â€˜å¤§æµ·â€™, â€˜æ˜¥è‰²â€™, â€˜è½èŠ±â€™]
[â€˜æ–œé˜³â€™]
[â€˜ç©ºä¸­â€™, â€˜å®¶ä¸­â€™]
[â€˜é«˜æ¥¼â€™, â€˜æ¥¼é˜â€™, â€˜æ¥¼å°â€™, â€˜é«˜å±±â€™, â€˜å±±ä¸Šâ€™, â€˜å±±å³¦â€™]
[â€˜å°è·¯â€™, â€˜å°èˆ¹â€™]
[â€˜åŸå¤–â€™, â€˜å®«ä¸­â€™, â€˜æ¸¡å£â€™, â€˜æ±Ÿä¸Šâ€™]
[â€˜é—¨å‰â€™, â€˜çª—å¤–â€™, â€˜æ±Ÿè¾¹â€™, â€˜å¤´ä¸Šâ€™, â€˜åœ°ä¸Šâ€™, â€˜æå¤´â€™]
[â€˜äººå®¶â€™]
[â€˜é»„æ²³â€™, â€˜é•¿æ±Ÿâ€™]
[â€˜æ±Ÿé¢â€™, â€˜æ°´é¢â€™]
[â€˜å±±æ°´â€™]
[â€˜å±±ä¸­â€™, â€˜å±±è°·â€™, â€˜åŸé‡â€™]
[â€˜å±±æ—â€™, â€˜é‡è‰â€™, â€˜æ ‘æ—â€™]
[â€˜é‡å¤–â€™]
[â€˜æ˜¥å…‰â€™, â€˜èŠ±å„¿â€™, â€˜èŠ³è‰â€™]
[â€˜æµ®äº‘â€™, â€˜äº‘é›¾â€™]
[â€˜ä¸œé£â€™]
[â€˜ç‹‚é£â€™, â€˜å¤§é›ªâ€™]
[â€˜éœ²ç â€™]
[â€˜ç¾é…’â€™]
[â€˜æ æ†â€™, â€˜çª—æˆ·â€™]
[â€˜è½¦é©¬â€™]
[â€˜è¡£è£³â€™, â€˜è¡£è¡«â€™, â€˜ç¾½æ¯›â€™]
[â€˜å¤´å‘â€™]
[â€˜çµç¶â€™]
[â€˜èŠ±æœµâ€™, â€˜é²œèŠ±â€™, â€˜èŠ±ä¸›â€™, â€˜æ ‘æâ€™, â€˜è´è¶â€™]
[â€˜è‰æœ¨â€™]
[â€˜æ ‘æœ¨â€™, â€˜èŠ±è‰â€™]
[â€˜å¤§é›â€™, â€˜éªé©¬â€™, â€˜ä¹Œé¸¦â€™]
[â€˜é±¼å„¿â€™]
[â€˜ç¾å¥³â€™, â€˜ç¾äººâ€™]
[â€˜å¦»å­â€™, â€˜å„¿å­â€™]
[â€˜çˆ¶æ¯â€™]
[â€˜å°†å†›â€™]
[â€˜çš‡ä¸Šâ€™]
[â€˜æˆ˜å£«â€™, â€˜å£«å…µâ€™]
[â€˜å†›é˜Ÿâ€™, â€˜æˆ˜äº‰â€™]
[â€˜æ­Œèˆâ€™, â€˜æ­Œå”±â€™]
[â€˜é¥®é…’â€™]
[â€˜å¼¹å¥â€™]</p>

<p>0.9
[â€˜æœˆå…‰â€™, â€˜æœˆè‰²â€™, â€˜å¤•é˜³â€™, â€˜åŸé‡â€™, â€˜å¤§æµ·â€™, â€˜æ˜¥è‰²â€™, â€˜äº‘é›¾â€™, â€˜å¾®é£â€™, â€˜éœ²ç â€™, â€˜å½±å­â€™, â€˜ç¾½æ¯›â€™, â€˜èŠ±æœµâ€™, â€˜è½èŠ±â€™, â€˜èŠ³è‰â€™, â€˜å¤§é›â€™, â€˜é±¼å„¿â€™, â€˜è´è¶â€™, â€˜çœ¼æ³ªâ€™]</p>

<p>[â€˜æ–œé˜³â€™, â€˜è½æ—¥â€™]</p>

<p>[â€˜é“¶æ²³â€™, â€˜é»„æ²³â€™, â€˜æ±Ÿä¸Šâ€™]</p>

<p>[â€˜æ¥¼é˜â€™, â€˜é«˜æ¥¼â€™, â€˜æ¥¼å°â€™, â€˜å°é˜¶â€™]</p>

<p>[â€˜é“è·¯â€™]</p>

<p>[â€˜äº¬åŸâ€™, â€˜åŸå¤–â€™, â€˜å®«ä¸­â€™]</p>

<p>[â€˜æˆ¿å±‹â€™]</p>

<p>[â€˜çª—å¤–â€™, â€˜ç©ºä¸­â€™, â€˜å®¶ä¸­â€™, â€˜æ±Ÿè¾¹â€™, â€˜å¤´ä¸Šâ€™, â€˜åœ°ä¸Šâ€™, â€˜è¡£è¥Ÿâ€™, â€˜æå¤´â€™]</p>

<p>[â€˜æ°´è¾¹â€™, â€˜é—¨å‰â€™]</p>

<p>[â€˜æ˜¥æ°´â€™, â€˜æ˜¥å…‰â€™]</p>

<p>[â€˜æ³‰æ°´â€™, â€˜æ¸¡å£â€™, â€˜æ°´é¢â€™, â€˜æ²³æ°´â€™]</p>

<p>[â€˜å±±è°·â€™, â€˜é«˜å±±â€™, â€˜å±±å³°â€™, â€˜å±±å³¦â€™, â€˜æ²™æ´²â€™, â€˜é‡è‰â€™, â€˜æ ‘æ—â€™, â€˜æ ‘æâ€™]</p>

<p>[â€˜ç»†é›¨â€™, â€˜å¤§é›ªâ€™, â€˜èŠ±å„¿â€™]</p>

<p>[â€˜çƒŸé›¾â€™, â€˜ç‹‚é£â€™, â€˜é²œèŠ±â€™]</p>

<p>[â€˜å¯’é£â€™]</p>

<p>[â€˜ç¾é…’â€™, â€˜ç¾å¥³â€™]</p>

<p>[â€˜æ æ†â€™, â€˜çª—æˆ·â€™]</p>

<p>[â€˜è½¦é©¬â€™, â€˜å±±æ°´â€™, â€˜è¡£è£³â€™, â€˜è‰æœ¨â€™, â€˜éªé©¬â€™]</p>

<p>[â€˜é»„é‡‘â€™]</p>

<p>[â€˜çº¢èŠ±â€™, â€˜èŠ±ä¸›â€™, â€˜è·å¶â€™]</p>

<p>[â€˜ææ¡â€™, â€˜èŠ±è‰â€™]</p>

<p>[â€˜é¸³é¸¯â€™, â€˜æµ®äº‘â€™, â€˜ç¾äººâ€™]</p>

<p>[â€˜å„¿å­â€™, â€˜å¦»å­â€™]</p>

<p>[â€˜äº²äººâ€™]</p>

<p>[â€˜è¡Œäººâ€™]</p>

<p>[â€˜å¤©å­â€™]</p>

<p>[â€˜å£«å…µâ€™, â€˜å°èˆ¹â€™, â€˜æˆ˜å£«â€™, â€˜å†›é˜Ÿâ€™, â€˜æˆ˜äº‰â€™]</p>

<p>[â€˜æ­Œå£°â€™, â€˜æ­Œå”±â€™]</p>

<p>[â€˜é¥®é…’â€™]</p>

<p>[â€˜å¼¹å¥â€™, â€˜çµç¶â€™]</p>

<p>0.85
[â€˜æœˆå…‰â€™, â€˜æœˆè‰²â€™, â€˜æ–œé˜³â€™, â€˜å¤ªé˜³â€™, â€˜é“¶æ²³â€™, â€˜æ¥¼å°â€™, â€˜åŸå¤–â€™, â€˜å®«ä¸­â€™, â€˜æ¸¡å£â€™, â€˜æ°´é¢â€™, â€˜æ±Ÿé¢â€™, â€˜æ˜¥æ°´â€™, â€˜å±±æ°´â€™, â€˜é«˜å±±â€™, â€˜å±±ä¸Šâ€™, â€˜å±±æ—â€™, â€˜æ²™æ´²â€™, â€˜æ˜¥å…‰â€™, â€˜ç»†é›¨â€™, â€˜çƒŸé›¾â€™, â€˜ä¸œé£â€™, â€˜ç‹‚é£â€™, â€˜éœ²ç â€™, â€˜ç§¯é›ªâ€™, â€˜é…’æ¯â€™, â€˜çª—æˆ·â€™, â€˜è½¦é©¬â€™, â€˜è¡£è£³â€™, â€˜å½±å­â€™, â€˜é»„é‡‘â€™, â€˜ç¾½æ¯›â€™, â€˜èŠ±æœµâ€™, â€˜è½èŠ±â€™, â€˜èŠ±ä¸›â€™, â€˜èŠ³è‰â€™, â€˜æ ‘æ—â€™, â€˜æ ‘æâ€™, â€˜è·å¶â€™, â€˜å¤§é›â€™, â€˜éªé©¬â€™, â€˜ä¹Œé¸¦â€™, â€˜ç¾å¥³â€™, â€˜å£«å…µâ€™, â€˜æ­Œå£°â€™, â€˜çœ¼æ³ªâ€™, â€˜æ¼«æ­¥â€™]</p>

<p>[â€˜å¤•é˜³â€™, â€˜è½æ—¥â€™, â€˜å°è·¯â€™, â€˜é»„æ²³â€™, â€˜æ±Ÿä¸Šâ€™, â€˜å±±ä¸­â€™, â€˜å±±è°·â€™, â€˜åŸé‡â€™, â€˜å¤§æµ·â€™, â€˜æµ®äº‘â€™, â€˜å¾®é£â€™, â€˜å¤§é›ªâ€™, â€˜å°èˆ¹â€™, â€˜çµç¶â€™, â€˜çº¢èŠ±â€™, â€˜é‡è‰â€™, â€˜æ¢§æ¡â€™, â€˜é±¼å„¿â€™, â€˜ç¾äººâ€™, â€˜æˆ˜å£«â€™]</p>

<p>[â€˜æ¥¼é˜â€™, â€˜é«˜æ¥¼â€™, â€˜æˆ¿å±‹â€™, â€˜æ³‰æ°´â€™, â€˜å±±å³¦â€™, â€˜æ æ†â€™, â€˜é²œèŠ±â€™, â€˜èŠ±è‰â€™, â€˜ææ¡â€™, â€˜å®¢äººâ€™]</p>

<p>[â€˜äº¬åŸâ€™, â€˜ç©ºä¸­â€™, â€˜å®¶ä¸­â€™, â€˜è¾¹å¡â€™, â€˜æ˜¥è‰²â€™, â€˜å†›é˜Ÿâ€™, â€˜æ­Œå”±â€™, â€˜æ¸¸ç©â€™, â€˜æˆ˜äº‰â€™]</p>

<p>[â€˜çª—å¤–â€™, â€˜é—¨å‰â€™, â€˜æ±Ÿè¾¹â€™, â€˜å¤´ä¸Šâ€™, â€˜åœ°ä¸Šâ€™, â€˜å¯’é£â€™, â€˜è¡£è¥Ÿâ€™, â€˜æå¤´â€™]</p>

<p>[â€˜æ²³æ°´â€™, â€˜é•¿æ±Ÿâ€™]</p>

<p>[â€˜äº‘é›¾â€™, â€˜ç¾é…’â€™, â€˜è¡£è¡«â€™, â€˜èŠ±å„¿â€™, â€˜é¸³é¸¯â€™]</p>

<p>[â€˜å¤´å‘â€™, â€˜æ°´è¾¹â€™]</p>

<p>[â€˜è´è¶â€™, â€˜è‰æœ¨â€™]</p>

<p>[â€˜å¦»å­â€™, â€˜å„¿å­â€™, â€˜çˆ¶æ¯â€™]</p>

<p>[â€˜å°†å†›â€™, â€˜å¤©å­â€™, â€˜å¤ªå®ˆâ€™]</p>

<p>[â€˜åŒˆå¥´â€™]</p>

<p>[â€˜é¥®é…’â€™]</p>

<h1 id="æ€»ç»“">æ€»ç»“ï¼š</h1>

<h4 id="1-æ˜æ˜¾çœ‹å‡ºè‡ªç”±è¡Œåº¦å‡å’Œåº¦å‡è‡ªç”±è¡Œçš„ç›¸ä¼¼åº¦æ˜¯é«˜äºå‰ä¸¤ä¸ªçš„è¯æ˜bertä½“ç³»å¯ä»¥å¾ˆå¥½èµ·åˆ°ç¼–è¾‘è·ç¦»çš„ä½œç”¨">1. æ˜æ˜¾çœ‹å‡ºè‡ªç”±è¡Œåº¦å‡å’Œåº¦å‡è‡ªç”±è¡Œçš„ç›¸ä¼¼åº¦ï¼Œæ˜¯é«˜äºå‰ä¸¤ä¸ªçš„ï¼Œè¯æ˜BERTä½“ç³»å¯ä»¥å¾ˆå¥½èµ·åˆ°ç¼–è¾‘è·ç¦»çš„ä½œç”¨ã€‚</h4>
<h4 id="2-æ ¹æ®èšç±»çš„å…³é”®æ˜¯ç”±ç›¸ä¼¼åº¦çš„åº¦é‡å†³å®šä¸ºäº†è·å–æ›´å¥½çš„è¯å‘é‡ç©ºé—´åº”è¯¥æ›´å¤šåœ°ä½¿ç”¨metrciä»»åŠ¡çš„finetuneæ•´ä¸ªbertæ¨¡å‹">2. æ ¹æ®èšç±»çš„å…³é”®æ˜¯ç”±ç›¸ä¼¼åº¦çš„åº¦é‡å†³å®šï¼Œä¸ºäº†è·å–æ›´å¥½çš„è¯å‘é‡ç©ºé—´ï¼Œåº”è¯¥æ›´å¤šåœ°ä½¿ç”¨metrciä»»åŠ¡çš„finetuneæ•´ä¸ªbertæ¨¡å‹.</h4>
<h4 id="3-æ­£å¦‚bm25bertæ¨¡å‹åº”ç”¨äºæ–‡æœ¬æœç´¢bertå¯ä»¥ä½œä¸ºæ™®é€‚åœ°è¯åµŒå…¥ç©ºé—´åˆå§‹å‚æ•°æ•´ä½“çš„ä»»åŠ¡åº”è¯¥é¢å‘å…·ä½“ä»»åŠ¡åœºæ™¯è¿›è¡Œè¿‡æ‹Ÿåˆçš„finetuneè®­ç»ƒæ‰“é€ ç‰¹æ®Šé¢†åŸŸçš„è¯å‘é‡è¡¨ç¤ºå¾ˆé•¿æ—¶é—´å†…å°†ä¼šæ˜¯nlpå„å¤§nluä»»åŠ¡çš„å‘å±•å’Œæ¢ç´¢æ–¹å‘æŒç»­éœ¸æ¦œå„å¤§ä»»åŠ¡çš„sota">3. æ­£å¦‚BM25+Bertæ¨¡å‹ï¼Œåº”ç”¨äºæ–‡æœ¬æœç´¢ï¼ŒBertå¯ä»¥ä½œä¸ºæ™®é€‚åœ°è¯åµŒå…¥ç©ºé—´åˆå§‹å‚æ•°ã€‚æ•´ä½“çš„ä»»åŠ¡åº”è¯¥ï¼Œé¢å‘å…·ä½“ä»»åŠ¡åœºæ™¯è¿›è¡Œè¿‡æ‹Ÿåˆçš„finetuneè®­ç»ƒï¼Œæ‰“é€ ç‰¹æ®Šé¢†åŸŸçš„è¯å‘é‡è¡¨ç¤ºï½ï½ï¼Œå¾ˆé•¿æ—¶é—´å†…å°†ä¼šæ˜¯NLPå„å¤§NLUä»»åŠ¡çš„å‘å±•å’Œæ¢ç´¢æ–¹å‘ï¼ŒæŒç»­éœ¸æ¦œå„å¤§ä»»åŠ¡çš„SOTA.</h4>

<ol>
  <li>N-gram è·ç¦»ï¼ˆBLEUæ ¸å¿ƒæ€æƒ³ï¼‰
Similarity  = |Gn(S)|+|Gt(T)|-2<em>|Gn(S)|</em>|Gn(T)|
å­—ç¬¦ä¸²å®Œå…¨ç›¸ç­‰ == 0</li>
</ol>

<ul>
  <li>ä¸­å›½è¶³åå’Œä¸­å›½è¶³çƒçš„å‘é‡ç›¸ä¼¼åº¦: 0.94828343</li>
  <li>ä¸­å›½è¶³åå’Œä¸­å›½ç¯®åçš„å‘é‡ç›¸ä¼¼åº¦: 0.9531492</li>
  <li>ä¸­å›½è¶³åå’Œè¶³åä¸­å›½çš„å‘é‡ç›¸ä¼¼åº¦ 0.9493892</li>
  <li>ç¾ä¸½ä¸­å›½å’Œä¸­å›½ç¾ä¸½çš„å‘é‡ç›¸ä¼¼åº¦ 0.95919204</li>
  <li>è‡ªç”±è¡Œåº¦å‡å’Œåº¦å‡è‡ªç”±è¡Œç›¸ä¼¼åº¦: 0.97110826
ç›¸å¯¹äºN-gramçš„è·ç¦»ï¼ŒåŠ å…¥æ›´å¤šè¯­ä¹‰ä¿¡æ¯ä½œä¸ºè¯çš„è¡¨ç¤º</li>
</ul>

<ol>
  <li>
    <p>BM25 
OKapi BM25 (BMä»£è¡¨æœ€ä½³åŒ¹é…ï¼‰æ˜¯æœç´¢å¼•æ“æ ¹æ®å…¶ä¸ç»™å®šçš„æœç´¢æŸ¥è¯¢çš„ç›¸å…³æ€§å¯¹åŒ¹é…æ–‡æ¡£è¿›è¡Œæ’åçš„æ’åå‡½æ•°ã€‚Stenphen E. Robertson å’ŒKarenSparckJones ç­‰äººå¼€å‘çš„æ¦‚ç‡æ£€ç´¢æ¡†æ¶ã€‚
query -&gt; è‹¥å¹²ç»“æœDï¼Œ</p>
  </li>
  <li>
    <p>WMD
EMD åœ¨NLPé¢†åŸŸçš„å»¶ä¼¸ã€‚EMDè·ç¦»æ˜¯ä¸€ç±»è¿è¾“é—®é¢˜ã€‚ 
WMDæ˜¯2015å¹´æå‡ºçš„ä¸€ç§è¡¡é‡æ–‡æœ¬ç›¸ä¼¼åº¦çš„æ–¹æ³•ï¼Œworld  Moverâ€™s Distance@ (ç®€ç§°)WMD ,è¯ç§»è·ç¦»ï¼Œåº¦é‡ä¸¤ä¸ªæ–‡æ¡£ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œå³WMDè·ç¦»è¶Šå°ç›¸ä¼¼åº¦è¶Šå¤§ã€‚</p>
  </li>
</ol>

<p>DOC2VECï¼Œ simHashåŸç†ä»‹ç»</p>

<h1 id="bertå‡ºç°å‰2016å¹´çš„kaggleæ–‡æœ¬ç›¸ä¼¼åº¦å¤§èµ›çš„å† å†›æ–¹æ¡ˆ">Bertå‡ºç°å‰2016å¹´çš„kaggleæ–‡æœ¬ç›¸ä¼¼åº¦å¤§èµ›çš„å† å†›æ–¹æ¡ˆï½</h1>
<h3 id="è¿™ä¸ªæ–¹æ¡ˆé›†æˆäº†å¤šç§ä¼ ç»Ÿç‰¹å¾æå–æ–¹æ¡ˆä½¿ç”¨äº†bertä¹‹å‰æœ€å¥½çš„è¯å‘é‡è¡¨å¾æ–¹æ¡ˆglove-ç»“åˆçŸ©é˜µåˆ†è§£å’Œword2vec-çš„è¯å‘é‡ç”Ÿæˆæ–¹æ¡ˆ">è¿™ä¸ªæ–¹æ¡ˆé›†æˆäº†å¤šç§ä¼ ç»Ÿç‰¹å¾æå–æ–¹æ¡ˆï¼Œä½¿ç”¨äº†Bertä¹‹å‰æœ€å¥½çš„è¯å‘é‡è¡¨å¾æ–¹æ¡ˆGlove, ç»“åˆçŸ©é˜µåˆ†è§£å’Œword2vec çš„è¯å‘é‡ç”Ÿæˆæ–¹æ¡ˆã€‚</h3>
<p># the some ideas  from</p>
<ol>
  <li>Features 
    three kind of featuresï¼š
        1.  word embedding 
        2. Sentence embeddings (Doc2Vec,  Sent2Vec)
        3.  Encode question pair using dense layer from ESIM model trained on SNLI</li>
  <li>Classical text mining features
    <ul>
      <li>Similarity meatures  on LDA  and LSI embedding</li>
      <li>Similarity meatures on bag of character n-grams (TFIDF reweighted or not )  from 1 to 8 gram</li>
      <li>Abhishekâ€™s and owlâ€™s kindly shared features</li>
      <li>
        <p>Edit and sequence matching distance ,  percentage of  common tokens up to 1,2,â€¦..,6 when question ends the same,  or starts the same</p>
      </li>
      <li>Length of  questions, diff of  legnth</li>
      <li>Number of capital letters,  question marks etcâ€¦</li>
      <li>Indicators  for  Question 1/2 starting  with  â€œareâ€,â€ Canâ€, â€œHowâ€ etc â€¦. and all mathematical engineering corresponding</li>
    </ul>
  </li>
</ol>

<h3 id="tokenizer--stanford-corenlp-to-tokenizer">Tokenizer : stanford corenlp to tokenizer</h3>
<h3 id="postagger-and-ner---postagger-and--ner-to-preprocessing-text-input-for-some-deep-learning-models">Postagger and Ner :  postagger and  ner to preprocessing text input for some deep learning models</h3>

<h1 id="structural-features-ie-from-graph">Structural features (i.e from graph)</h1>
<h4 id="ä½¿ç”¨å›¾æå–ç‰¹å¾">ä½¿ç”¨å›¾æå–ç‰¹å¾</h4>
<h4 id="å¦‚ä½•å»ºå›¾å’Œä½¿ç”¨å›¾æå–ç‰¹å¾">å¦‚ä½•å»ºå›¾å’Œä½¿ç”¨å›¾æå–ç‰¹å¾ï½</h4>
<ol>
  <li>
    <p>We  built density features from the graph built  from the edges  between pairs of questions inside  train and  test datasets  concatenated.</p>
  </li>
  <li>
    <p>We  had  counts  of   neighbors  of  question  1,  question  2,  the min,  the max,  intersections, unions,  shortest  path  length  when main edge cutâ€¦..</p>
  </li>
  <li>
    <p>We went further  and built density features to count the neighbors of  the  questions neighborsâ€¦.. and  questions neighbors neighbors â€¦ (inception)</p>
  </li>
  <li>
    <p>We also counted neighbors  of higher order which also were  neighbors  of  lower  order (loops)</p>
  </li>
  <li>
    <p>We tried  different  graph  structures  :  we built undirected and directed  graphs  (edges  directed from question 1 to question 2 ),  we  also tried to separate the  density features  of question 1 from the features  of  question 2 to generate non commutativeï¼ˆäº¤æ¢çš„ï¼‰features  in addition to commutative ones</p>
  </li>
  <li>
    <p>We built features describing the connex((è¿é€š) subgraph the pair belonged to :  Number of edges ,  number of nodes, % of  edge in train</p>
  </li>
  <li>
    <p>We also computed the same features on subgrphs built only from the edges of questions which both appear more than once.æˆ‘ä»¬æƒ³åšçš„æ˜¯ç§»é™¤fake questions which we thought were damaging the graph features by changing its  structure.</p>
  </li>
  <li>
    <p>æœ€åï¼Œæˆ‘ä»¬ç»™graph å¢åŠ äº†æƒé‡ï¼Œ æˆ‘ä»¬ä½¿ç”¨äº†ä¸€ç§æˆ‘ä»¬ç›¸ä¼¼åº¦çš„ç‰¹å¾ç»™æˆ‘ä»¬çš„graphå¢åŠ æƒé‡ã€‚</p>
  </li>
</ol>

<h1 id="models">Models</h1>

<ol>
  <li>
    <p>We worked on two main  architectures for our NNets: Siamese and Attention Neutral Networks.</p>
  </li>
  <li>
    <p>Siamese LSTM with pretrained GLOVE embedding</p>
  </li>
  <li>
    <p>Decomposable attention with pretrained FastText embedding . This model achive ~0.3 on cv</p>
  </li>
  <li>
    <p>ESIM with pretrained FastText embedding .  this is our best pure Deep Learning NLP model ,  it achieves ~ 0.27 on CV.  However this model take too long to run , we only add it once in the first stacking layer</p>
  </li>
  <li>
    <p>We noticed that DL complex  works on the first stacking layer but did not do better than simple  MLP  on second  layer</p>
  </li>
</ol>

<h1 id="bertæ–‡æœ¬ç›¸ä¼¼æ€§çš„å…¸å‹æ¡ˆä¾‹-åˆ©ç”¨é¢„è®­ç»ƒçš„ä¸­æ–‡æ¨¡å‹å®ç°åŸºäºbertçš„è¯­ä¹‰åŒ¹é…æ¨¡å‹-æ•°æ®é›†ä¸ºlcqmcæ•°æ®é›†">Bertæ–‡æœ¬ç›¸ä¼¼æ€§çš„å…¸å‹æ¡ˆä¾‹ åˆ©ç”¨é¢„è®­ç»ƒçš„ä¸­æ–‡æ¨¡å‹å®ç°åŸºäºBertçš„è¯­ä¹‰åŒ¹é…æ¨¡å‹ æ•°æ®é›†ä¸ºLCQMCæ•°æ®é›†</h1>
<p>https://github.com/pengming617/bert_textMatching</p>

<h1 id="lstmå¥å­ç›¸ä¼¼åº¦åˆ†æ">LSTMå¥å­ç›¸ä¼¼åº¦åˆ†æ</h1>
<p>https://github.com/zqhZY/semanaly</p>

<h1 id="query-çš„è§„åˆ™åŒ¹é…">query çš„è§„åˆ™åŒ¹é…</h1>
<h4 id="é€Ÿåº¦å¿«-å¯æ§æ˜“äºå®ç°é«˜æ•ˆ">é€Ÿåº¦å¿«ï¼Œ å¯æ§ï¼Œæ˜“äºå®ç°ï¼Œé«˜æ•ˆã€‚</h4>
<ol>
  <li>ä¸FAQåº“ä¸­çš„æ ‡é—®å’Œç›¸ä¼¼æ–‡é—®ï¼Œ è¿›è¡Œåˆ†è¯ã€æç‚¼å‡ºå¤§é‡çš„æ¦‚å¿µï¼Œå¹¶å°†ä¸Šè¿°æ¦‚å¿µç»„åˆï¼Œæ„æˆå¤§é‡çš„å¥å¼ï¼Œ
 åä¸ºmate30 æ˜¯cellphoneæ¦‚å¿µï¼Œaskmoneyæ¦‚å¿µ-ï¼Œ â€œç°åœ¨â€ æ˜¯æ—¶é—´æ¦‚å¿µã€‚</li>
</ol>

<h1 id="æ·±åº¦å­¦ä¹ è¯­ä¹‰åŒ¹é…">æ·±åº¦å­¦ä¹ è¯­ä¹‰åŒ¹é…</h1>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DSSMï½ LSTM-DSSM
åŸºäºBERTç­‰é¢„è®­ç»ƒæ¨¡å‹   #   Knowledge Based Question &amp;Answer   åŸºäºçŸ¥è¯†ä½“ç³»çš„é—®ç­”ç³»ç»Ÿ
</code></pre></div></div>

<p>KBQA æœ€å…³é”®ä¸€æ­¥åœ¨äºKGçš„æ­å»ºï¼Œå¯¹ç»å¤§éƒ¨åˆ†NLPä»»åŠ¡éƒ½æœ‰æå¤§æå¤§çš„åŠ æˆã€‚
  # åŸºäºçŸ¥è¯†å›¾è°±çš„è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…å’Œæ™ºèƒ½æœç´¢åº”ç”¨</p>

:ET